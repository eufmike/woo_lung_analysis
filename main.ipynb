{"cells":[{"cell_type":"markdown","source":[" # Lung Vasculature Analysis\n"," This notebook (.ipynb) is a working project for analyzing lung vasculature. It inculdes three parts:\n"," 1. converts skeleton analytical output (.xml) into .csv file.\n"," 2. calulates the length and average thickness of each segment.\n"," 3. makes two types of plots:\n","     1. histogram of each dataset on length and thickness\n","     2. average histogram on length and thickness (line plot with error bars)\n",""],"metadata":{}},{"source":["get_ipython().run_line_magic('load_ext', 'autoreload')\n","get_ipython().run_line_magic('autoreload', '2')\n","import os, sys, re, io\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import time\n","from core.fileop import DirCheck, ListFiles\n","import core.mkplot as mkplot \n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["  ## Part 1:\n","  Converting skeleton analytical output (.xml) into .csv file.\n","  * Inputs: *.xml\n","  * Outputs: *.csv\n","  * Dependencies: xml, time, pandas, tqdm </br>\n","\n","  * *.xml file includes three sheets: nodes, points, and segments.\n","  * Warning: the progress bar controled by `tqdm` is not functioning well. It can not overwrite itself and creates multiple lines."],"metadata":{}},{"cell_type":"markdown","source":[" ### Functions"],"metadata":{}},{"source":["# import dependencies\n","import xml.etree.ElementTree as etree\n","from core.msxml import MSXmlReader\n","\n","# function\n","def convert_xml_csv(ippath, oppath):\n","    filelist, fileabslist = ListFiles(ippath, extension='.xml')\n","    \n","    for idx, f in enumerate(filelist):\n","        filename = f.replace('.xml', '')\n","        ip = os.path.join(ippath, f) \n","        op = os.path.join(oppath, filename)\n","        \n","        print(ip)\n","        print(op)\n","\n","        # create path\n","        if filename not in os.listdir(oppath):\n","            DirCheck(op)\n","            \n","            # convert *.xml to *.csv \n","            csv_all = MSXmlReader(ip)\n","            \n","            # save each spreadsheet into individual *.csv file\n","            for key, value in csv_all.items():\n","                oppath_tmp = os.path.join(op, key + '.csv')\n","                value.to_csv(oppath_tmp, index = False)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Execution\n"," To run the code, please change `path` to the directory hosts the raw data."],"metadata":{}},{"source":["path = '/Volumes/LaCie_DataStorage/Woo-lungs/2019'\n","ipdir = 'raw'\n","opdir = 'csv'\n","ippath = os.path.join(path, ipdir)\n","oppath = os.path.join(path, opdir)\n","# make dir\n","DirCheck(oppath)\n","\n","# convert files in batch\n","convert_xml_csv(ippath, oppath)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["  ## Part 2:\n","  Calulating the length and average thickness of each segment.\n","  * Inputs: nodes.csv, points.csv, segments.csv\n","  * Outputs: segments_s.csv\n","\n","  `SegStats` extracts euclidean coordinates and thickness of each point, then calculate the total length and average thickness."],"metadata":{}},{"cell_type":"markdown","source":[" ### Functions"],"metadata":{}},{"source":["# load dependencies\n","from core.filamentanalysis import SegStats\n","\n","# function\n","def stats_calculator(ippath, oppath):\n","    imglist = [x for x in os.listdir(ippath) if not x.startswith('.')]\n","    \n","    var = ['df_nodes', 'df_points', 'df_segments']\n","    for img in imglist:\n","        filelist, fileabslist = ListFiles(os.path.join(ippath, img), extension='.csv')\n","        \n","        df_points = pd.read_csv(os.path.join(ippath, img, 'points.csv')) \n","        df_segments = pd.read_csv(os.path.join(ippath, img, 'segments.csv')) \n","        \n","        opfilename = 'segments_s.csv'\n","    \n","        if opfilename not in filelist:\n","            df_segments_s = SegStats(df_points, df_segments)            \n","            df_segments_s.to_csv(os.path.join(oppath, img, opfilename), index = False)\n","                \n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ### Execution\n"," To run the code, please change `path` to the directory hosts the raw data."],"metadata":{}},{"source":["path = '/Volumes/LaCie_DataStorage/Woo-lungs/2019'\n","ipdir = 'csv'\n","opdir = 'csv'\n","ippath = os.path.join(path, ipdir)\n","oppath = os.path.join(path, opdir)\n","# make dir\n","DirCheck(oppath)\n","\n","# convert files in batch\n","stats_calculator(ippath, oppath)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ## Part 3:\n"," Creating two sets of plots:\n"," 1. histogram of each dataset on length and thickness\n"," 2. average histogram on length and thickness (line plot with error bars)\n","\n","  * Inputs: segments_s.csv\n","  * Outputs:\n","      1. `histo/length/*.png`: frequency - length (µm)\n","      2. `histo/thickness/*.png`: frequency - thickness (µm)\n","      3. `histo_summary/length.png`: histogram in line plot style\n","      4. `histo_summary/thickness.png`: histogram in line plot style\n","\n","  `SegStats` extracts euclidean coordinates and thickness of each point, then calculate\n"," the total length and average thickness.\n","\n","\n"," In the ouputs, the code renames \"thickness\" to \"radius\" to avoid confusion. Quotes from\n"," Amira User's Manual\n"," > As an estimate of the local thickness, the closest distance to the label\n"," boundary (boundary distance map) is stored at every point in the *Spatial Graph*.\n"," The attribute is named *thickness* and constitutes the *radius* of the circular cross-section\n"," of the filament at a given point of the centerline."],"metadata":{}},{"source":["# import depandencies\n","import matplotlib.pyplot as plt\n","import matplotlib.style as style\n","style.use('default')\n","import scipy.stats as stats\n","from core.mkplot import GroupImg, FindRange, IndividualHisto\n","from core.mkplot import make_individul_plots, make_merged_plots\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["path = '/Volumes/LaCie_DataStorage/Woo-lungs/2019'\n","ipdir = 'csv'\n","opdir1 = 'plot'\n","opdir2 = 'histogram'\n","subfolder = ['histo', 'histo_summary']\n","ippath = os.path.join(path, ipdir)\n","oppath = os.path.join(path, opdir1, opdir2)\n","for i in subfolder:\n","    oppath_sub = os.path.join(oppath, i)\n","    DirCheck(oppath_sub)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# load fileinfo\n","fileinfo = pd.read_csv(os.path.join('./par', 'lung_file_idx.csv'))\n","\n","columns = {\n","    'length': {\n","        'x_label': 'Length (µm)',\n","        'file_label': 'length',\n","    },\n","    'thickness': {\n","        'x_label': 'Radius (µm)',\n","        'file_label': 'radius',\n","    },\n","}\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# plot individual histogram\n","make_individul_plots(ippath, oppath, fileinfo, columns)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# plot merged histogram in counts\n","make_merged_plots(ippath, oppath, fileinfo, columns, frequency = False, x_max_factor = 0.07)\n","# plot merged histogram in frequency \n","make_merged_plots(ippath, oppath, fileinfo, columns, frequency = True, x_max_factor = 0.07)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# plot merged histogram in counts\n","make_merged_plots(ippath, oppath, fileinfo, columns, frequency = False, x_max_factor = 0.2)\n","# plot merged histogram in frequency \n","make_merged_plots(ippath, oppath, fileinfo, columns, frequency = True, x_max_factor = 0.2)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# plot merged histogram in counts\n","make_merged_plots(ippath, oppath, fileinfo, columns, frequency = False, x_max_factor = 1)\n","# plot merged histogram in frequency \n","make_merged_plots(ippath, oppath, fileinfo, columns, frequency = True, x_max_factor = 1)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}